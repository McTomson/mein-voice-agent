<!DOCTYPE html>
<html>
<head>
    <title>Mein Voice Agent</title>
    <style>
        #voice-agent {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 300px;
            height: 400px;
            background: #f0f0f0;
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 0 20px rgba(0,0,0,0.2);
            text-align: center;
        }
        #response {
            height: 70%;
            overflow-y: auto;
            margin-bottom: 10px;
            border: 1px solid #ddd;
            padding: 10px;
            background: white;
        }
        button {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 10px;
            border-radius: 5px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div id="voice-agent">
        <h2>Mein AI-Assistent</h2>
        <div id="response">DrÃ¼cken Sie "Sprechen" und fragen Sie mich etwas!</div>
        <button id="startButton">ðŸŽ¤ Sprechen</button>
    </div>

    <script>
        // HIER API-KEY UND VOICE-ID EINTRAGEN!
        const API_KEY = "sk_e66445a67349383a8bb0762bff27f63012b1253a7a8f6ae6";  // Ersetzen Sie dies mit Ihrem ElevenLabs-Key!
        const VOICE_ID = "kqVT88a5QfII1HNAEPTJ";  // Ersetzen Sie dies mit Ihrer Voice-ID!

        const startButton = document.getElementById("startButton");
        const responseDiv = document.getElementById("response");

        startButton.addEventListener("click", async () => {
            try {
                responseDiv.textContent = "HÃ¶re zu...";
                const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                recognition.lang = "de-DE";

                recognition.onresult = async (event) => {
                    const spokenText = event.results[0][0].transcript;
                    responseDiv.textContent = "Sie: " + spokenText;
                    const reply = await fetchElevenLabsVoice(spokenText);
                    responseDiv.innerHTML += "<br>AI: " + reply;
                };

                recognition.start();
            } catch (error) {
                responseDiv.textContent = "Fehler: " + error.message;
            }
        });

        async function fetchElevenLabsVoice(text) {
            try {
                const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}/stream`, {
                    method: "POST",
                    headers: {
                        "xi-api-key": API_KEY,
                        "Content-Type": "application/json",
                    },
                    body: JSON.stringify({
                        text: text,
                        voice_settings: { stability: 0.5, similarity_boost: 0.5 }
                    })
                });

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                audio.play();
                return "Antwort wird abgespielt...";
            } catch (error) {
                return "Fehler: " + error.message;
            }
        }
    </script>
</body>
</html>
